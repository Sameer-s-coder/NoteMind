# ğŸ“š NoteMind

*An AI-powered note manager that organizes, summarizes, and retrieves your notes.*

---

## ğŸš€ Overview

**NoteMind** is a CLI tool that helps you manage your notes intelligently using Generative AI.
With NoteMind, you can:

* Add and store raw notes
* Summarize them into clear, concise points
* Retrieve notes with semantic search (AI-powered)
* Generate study aids like flashcards
* Export structured outputs (JSON/Markdown)

This project demonstrates **prompt engineering, model controls, structured outputs, function calling, and embeddings** â€” making it both practical and portfolio-ready.

---

## âœ¨ Features

* ğŸ“ **Add Notes:** Store your raw notes directly via CLI.
* ğŸ” **Search with AI:** Retrieve contextually relevant notes using embeddings.
* ğŸ“‘ **Summarize:** Get concise bullet-point summaries of long notes.
* ğŸ“ **Flashcards:** Convert notes into questionâ€“answer flashcards.
* âš™ **Custom Controls:** Adjust temperature, top-k, and top-p for different styles.
* ğŸ“‚ **Structured Output:** Export summaries and notes in JSON/Markdown.

---

## ğŸ› ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/your-username/notemind.git
cd notemind

# Install dependencies
npm install   # (if Node.js version)
# or
pip install -r requirements.txt   # (if Python version)

# Set up environment variables
cp .env.example .env
```

Inside `.env`, add your API key (Gemini/OpenAI/etc.):

```
API_KEY=your_api_key_here
```

---

## âš¡ Usage

### Add a note

```bash
nm add "Neural networks mimic the human brain's neuron connections."
```

### Summarize notes

```bash
nm summarize
```

â¡ Output:

```
Topic: Neural Networks
Summary: NNs are AI models inspired by biological neurons, useful in pattern recognition.
```

### Search notes

```bash
nm search "What did I write about neural networks?"
```

### Generate flashcards

```bash
nm flashcards
```

â¡ Output:

```
Q: What do neural networks mimic?  
A: The connections of neurons in the human brain.
```

---

## âš™ï¸ CLI Commands

| Command         | Description                                |
| --------------- | ------------------------------------------ |
| `nm add`        | Add new notes                              |
| `nm summarize`  | Summarize all stored notes                 |
| `nm search`     | Retrieve notes using embeddings            |
| `nm flashcards` | Generate flashcards from notes             |
| `nm export`     | Export notes/summaries to JSON or Markdown |

---

## ğŸ“‚ Project Structure

```
notemind/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli.js        # CLI entry point
â”‚   â”œâ”€â”€ prompts/      # System & user prompts
â”‚   â”œâ”€â”€ embeddings/   # Vector search logic
â”‚   â”œâ”€â”€ utils/        # Helper functions
â”‚   â””â”€â”€ tests/        # Evaluation & tests
â”œâ”€â”€ README.md
â”œâ”€â”€ package.json / requirements.txt
â””â”€â”€ .env.example
```

---

## ğŸ§ª Testing

Run evaluation dataset against NoteMind to verify performance:

```bash
npm test
# or
pytest tests/
```

---

## ğŸ“– Roadmap

* [x] Add/Summarize notes
* [x] Search with embeddings
* [x] Flashcard generation
* [ ] Web UI version
* [ ] Cloud sync

---

## ğŸ¤ Contributing

Pull requests are welcome! Please open an issue first to discuss what youâ€™d like to change.

---

## ğŸ“œ License

MIT License Â© 2025 \[Your Name]

---
System and User Prompt :
        ğŸ‘‰ Example:

System: â€˜You are NoteMind, an AI note manager. Always answer in bullet points.â€™

User: â€˜Summarize this note: Neural networks mimic the brain.â€™
â¡ Output:
â€¢ Neural networks imitate brain neurons
â€¢ Useful in AI models

This shows how system and user prompts shape the AIâ€™s tone and structure.â€



Zero-Shot Prompting :
â€œNow letâ€™s look at Zero-Shot Prompting.
This is when we ask the model to answer without giving it any examples.

ğŸ‘‰ Example:
User: â€˜Explain overfitting in machine learning.â€™
â¡ Output: â€˜Overfitting happens when a model memorizes noise in the training data instead of learning patterns.â€™

As you can see, even with no examples, the model gives a clear answer. This is the foundation of AI-agent interactions.â€


One-Shot Prompting :
        â€œNext is One-Shot Prompting.
Here, we give the AI one example before asking our question.

ğŸ‘‰ Example:

Example:
User: â€˜Summarize: Decision trees split data.â€™
Model: â€˜â€¢ Definition â€¢ How it works â€¢ Usesâ€™

New Query:
User: â€˜Summarize underfitting.â€™
â¡ Output: â€˜â€¢ Too simple â€¢ Misses patterns â€¢ Poor accuracy.â€™

One example helps the model produce more structured and accurate answers.â€


Multi-Shot Prompting :

â€œNow letâ€™s see Multi-Shot Prompting.
This is when we provide multiple examples to guide the AIâ€™s response.

ğŸ‘‰ Example:
User provides:

Input: â€˜Linear Regressionâ€™ â†’ Flashcard: Q: What does it do? A: Predicts continuous values.

Input: â€˜Logistic Regressionâ€™ â†’ Flashcard: Q: What does it do? A: Classifies binary outcomes.

Then asks: â€˜Make flashcards from Gradient Descent.â€™
â¡ Output:
Q: What does Gradient Descent do?
A: Minimizes loss by iteratively updating parameters.

The more examples we provide, the more consistent the answers become.â€


Chain-of-Thought Prompting :

â€œNext is Chain-of-Thought Prompting.
Here, we encourage the model to reason step by step before giving the answer.

ğŸ‘‰ Example:
User: â€˜Explain the bias-variance tradeoff.â€™
The model first reasons internally:

Bias is error from strong assumptions.

Variance is error from sensitivity to data.

â¡ Final Output: â€˜The bias-variance tradeoff is about balancing simplicity and flexibility to achieve better generalization.â€™

This hidden reasoning makes the answer more accurate.â€